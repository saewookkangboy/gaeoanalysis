# AI 활용 고지 탐지 기능 기술 검토

## 1. 개요

현재 GAEO Analysis 시스템에 **AI 활용 고지 탐지(AI Disclosure Detection)** 기능을 추가하여 블로그 콘텐츠가 AI 생성 콘텐츠에 대한 적절한 고지를 포함하고 있는지 측정하는 새로운 분석 영역을 도입합니다.

### 1.1 목표
- 블로그 콘텐츠의 AI 활용 고지 여부 탐지
- Google SynthID 기반 워터마킹 탐지
- AI 윤리 기준 준수 여부 평가
- 종합적인 AI 투명성 점수 제공

### 1.2 배경
- **Google SynthID**: 2024년 Google DeepMind가 개발한 AI 생성 콘텐츠 워터마킹 기술
- **AI 윤리 규정**: EU AI Act, Colorado AI Act 등 글로벌 규정 강화
- **콘텐츠 투명성**: 사용자 신뢰 및 법적 준수를 위한 AI 활용 고지 필요성 증가

---

## 2. 현재 시스템 구조 분석

### 2.1 기존 측정 영역
현재 시스템은 다음 측정 영역을 제공합니다:

```typescript
interface AnalysisResult {
  aeoScore: number;           // Answer Engine Optimization
  geoScore: number;           // Generative Engine Optimization
  seoScore: number;           // Search Engine Optimization
  overallScore: number;      // 종합 점수
  aiVisibilityScore?: number; // AI 가시성 점수
  aioAnalysis?: AIOCitationAnalysis; // AI 모델별 인용 확률
  // ... 기타 필드
}
```

### 2.2 분석 파이프라인
1. **URL Fetch**: HTML 콘텐츠 가져오기
2. **Cheerio 파싱**: HTML 구조 분석
3. **점수 계산**: AEO/GEO/SEO 점수 계산
4. **AI 분석**: AI 모델별 인용 확률 계산
5. **인사이트 생성**: 개선 권장사항 생성

### 2.3 데이터베이스 스키마
```sql
-- analyses 테이블
CREATE TABLE analyses (
  id TEXT PRIMARY KEY,
  user_id TEXT,
  url TEXT,
  aeo_score INTEGER,
  geo_score INTEGER,
  seo_score INTEGER,
  overall_score INTEGER,
  ai_visibility_score INTEGER,
  -- AI 활용 고지 점수 필드 추가 필요
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

---

## 3. 기술 요구사항

### 3.1 AI 활용 고지 탐지 기능 구성요소

#### 3.1.1 명시적 고지 탐지 (Explicit Disclosure Detection)
- **목표**: 콘텐츠 내 AI 활용에 대한 명시적 언급 탐지
- **탐지 패턴**:
  - "AI로 작성됨", "AI 생성", "AI 활용"
  - "This content was generated by AI"
  - "AI-assisted", "AI-powered"
  - 메타 태그: `<meta name="ai-generated" content="true">`
  - 구조화된 데이터: `Article` 스키마의 `aiGenerated` 속성

#### 3.1.2 Google SynthID 워터마킹 탐지
- **목표**: Google SynthID로 워터마킹된 콘텐츠 탐지
- **기술적 접근**:
  - **텍스트 워터마킹**: 통계적 패턴 분석
  - **이미지 워터마킹**: 픽셀 레벨 워터마킹 탐지
  - **API 통합**: Google SynthID Detector API 활용 (가능한 경우)

#### 3.1.3 AI 윤리 기준 준수 평가
- **평가 항목**:
  1. **투명성 (Transparency)**: AI 활용 명시 여부
  2. **정확성 (Accuracy)**: 사실 확인 및 출처 명시
  3. **책임성 (Accountability)**: 작성자/편집자 정보
  4. **공정성 (Fairness)**: 편향성 고지
  5. **프라이버시 (Privacy)**: 개인정보 처리 고지

---

## 4. 구현 방안

### 4.1 새로운 분석 모듈 구조

```
lib/
├── ai-disclosure-detector.ts      # AI 활용 고지 탐지 메인 모듈
├── synthid-detector.ts            # Google SynthID 탐지 모듈
├── ai-ethics-analyzer.ts          # AI 윤리 기준 평가 모듈
└── disclosure-scorer.ts           # 종합 점수 계산 모듈
```

### 4.2 AI 활용 고지 탐지 모듈 (`ai-disclosure-detector.ts`)

```typescript
export interface AIDisclosureResult {
  hasExplicitDisclosure: boolean;
  disclosureType: 'explicit' | 'meta' | 'structured' | 'none';
  disclosureText?: string;
  disclosureLocation?: 'header' | 'footer' | 'body' | 'meta';
  confidence: number; // 0-100
}

export interface AIDisclosureAnalysis {
  explicitDisclosure: AIDisclosureResult;
  synthidDetection: SynthIDResult;
  ethicsCompliance: EthicsComplianceResult;
  overallDisclosureScore: number; // 0-100
  recommendations: string[];
}

/**
 * AI 활용 고지 탐지
 */
export function detectAIDisclosure($: cheerio.CheerioAPI, html: string): AIDisclosureResult {
  // 1. 명시적 텍스트 탐지
  const explicitPatterns = [
    /AI\s*(?:로|에\s*의해|를\s*사용하여|를\s*활용하여)\s*(?:작성|생성|제작)/i,
    /(?:This|This content|This article)\s+(?:was\s+)?(?:generated|created|written)\s+(?:by|using|with)\s+AI/i,
    /AI\s*(?:assisted|powered|generated|created)/i,
    /(?:생성형\s*)?AI\s*(?:콘텐츠|기술|도구)/i,
  ];

  const bodyText = $('body').text();
  const disclosureMatches = explicitPatterns.filter(pattern => pattern.test(bodyText));
  
  // 2. 메타 태그 탐지
  const metaAIGenerated = $('meta[name="ai-generated"], meta[property="ai:generated"]').attr('content');
  const hasMetaDisclosure = metaAIGenerated === 'true' || metaAIGenerated === 'yes';

  // 3. 구조화된 데이터 탐지
  const structuredData = $('script[type="application/ld+json"]').text();
  const hasStructuredDisclosure = /"aiGenerated"\s*:\s*true/i.test(structuredData);

  // 4. 위치 탐지
  let disclosureLocation: 'header' | 'footer' | 'body' | 'meta' = 'body';
  if (hasMetaDisclosure || hasStructuredDisclosure) {
    disclosureLocation = 'meta';
  } else if (disclosureMatches.length > 0) {
    // 헤더/푸터 영역 확인
    const headerText = $('header, .header, [class*="header"]').text();
    const footerText = $('footer, .footer, [class*="footer"]').text();
    
    if (explicitPatterns.some(p => p.test(headerText))) {
      disclosureLocation = 'header';
    } else if (explicitPatterns.some(p => p.test(footerText))) {
      disclosureLocation = 'footer';
    }
  }

  return {
    hasExplicitDisclosure: disclosureMatches.length > 0 || hasMetaDisclosure || hasStructuredDisclosure,
    disclosureType: hasStructuredDisclosure ? 'structured' : 
                     hasMetaDisclosure ? 'meta' : 
                     disclosureMatches.length > 0 ? 'explicit' : 'none',
    disclosureText: disclosureMatches.length > 0 ? bodyText.match(explicitPatterns[0])?.[0] : undefined,
    disclosureLocation,
    confidence: disclosureMatches.length > 0 ? 90 : 
                hasMetaDisclosure ? 85 : 
                hasStructuredDisclosure ? 95 : 0,
  };
}
```

### 4.3 Google SynthID 탐지 모듈 (`synthid-detector.ts`)

```typescript
export interface SynthIDResult {
  hasWatermark: boolean;
  watermarkType: 'text' | 'image' | 'video' | 'none';
  confidence: number; // 0-100
  detectedPatterns?: string[];
}

/**
 * Google SynthID 워터마킹 탐지
 * 
 * 참고: Google SynthID Detector는 현재 공개 API가 제한적이므로,
 * 통계적 패턴 분석을 통해 간접적으로 탐지합니다.
 */
export function detectSynthIDWatermark($: cheerio.CheerioAPI, html: string): SynthIDResult {
  const text = $('body').text();
  
  // SynthID 텍스트 워터마킹은 통계적 패턴을 사용하므로
  // 완벽한 탐지는 어렵지만, 일반적인 AI 생성 텍스트 패턴을 분석
  
  // 1. 텍스트 통계 분석
  const sentences = text.split(/[.!?]\s+/);
  const avgSentenceLength = sentences.reduce((sum, s) => sum + s.length, 0) / sentences.length;
  const wordVariety = new Set(text.toLowerCase().split(/\s+/)).size / text.split(/\s+/).length;
  
  // 2. AI 생성 텍스트 특징 (참고용, 정확도는 제한적)
  const aiIndicators = {
    uniformSentenceLength: avgSentenceLength > 15 && avgSentenceLength < 25, // 일정한 문장 길이
    lowWordVariety: wordVariety < 0.3, // 낮은 어휘 다양성
    repetitivePhrases: /(\b\w+\s+\w+\s+\w+\b).*\1/i.test(text), // 반복 구문
  };

  // 3. 이미지 워터마킹 탐지 (이미지 URL 분석)
  const images = $('img[src]');
  const imageUrls = images.map((_, el) => $(el).attr('src')).get();
  // 실제 SynthID 워터마킹은 픽셀 레벨 분석이 필요하므로 서버 측 이미지 분석 필요

  // 4. 메타데이터 확인
  const hasSynthIDMeta = $('meta[name="synthid"], meta[property="synthid:watermarked"]').length > 0;

  return {
    hasWatermark: hasSynthIDMeta || Object.values(aiIndicators).filter(Boolean).length >= 2,
    watermarkType: hasSynthIDMeta ? 'text' : 'none',
    confidence: hasSynthIDMeta ? 80 : 
                Object.values(aiIndicators).filter(Boolean).length >= 2 ? 40 : 0,
    detectedPatterns: hasSynthIDMeta ? ['meta-tag'] : 
                      Object.entries(aiIndicators)
                        .filter(([_, v]) => v)
                        .map(([k]) => k),
  };
}

/**
 * 향후 Google SynthID Detector API 통합 (API 제공 시)
 */
export async function detectSynthIDViaAPI(content: string): Promise<SynthIDResult> {
  // TODO: Google SynthID Detector API가 공개되면 통합
  // 현재는 공개 API가 없으므로 통계적 분석만 수행
  throw new Error('Google SynthID Detector API is not yet publicly available');
}
```

### 4.4 AI 윤리 기준 평가 모듈 (`ai-ethics-analyzer.ts`)

```typescript
export interface EthicsComplianceResult {
  transparency: {
    score: number; // 0-100
    hasDisclosure: boolean;
    issues: string[];
  };
  accuracy: {
    score: number;
    hasFactChecking: boolean;
    hasSources: boolean;
    issues: string[];
  };
  accountability: {
    score: number;
    hasAuthor: boolean;
    hasEditor: boolean;
    issues: string[];
  };
  fairness: {
    score: number;
    hasBiasDisclosure: boolean;
    issues: string[];
  };
  privacy: {
    score: number;
    hasPrivacyNotice: boolean;
    issues: string[];
  };
  overallScore: number; // 가중 평균
}

/**
 * AI 윤리 기준 준수 평가
 */
export function evaluateAIEthics($: cheerio.CheerioAPI, html: string): EthicsComplianceResult {
  const text = $('body').text();
  
  // 1. 투명성 (Transparency)
  const hasAIDisclosure = detectAIDisclosure($, html).hasExplicitDisclosure;
  const transparencyScore = hasAIDisclosure ? 100 : 0;
  
  // 2. 정확성 (Accuracy)
  const hasSources = /출처|참고|reference|source|citation/i.test(text) || 
                     $('a[href*="doi"], a[href*="arxiv"], a[href*="pubmed"]').length > 0;
  const hasFactChecking = /사실\s*확인|fact\s*check|검증/i.test(text);
  const accuracyScore = (hasSources ? 50 : 0) + (hasFactChecking ? 50 : 0);
  
  // 3. 책임성 (Accountability)
  const hasAuthor = $('meta[name="author"], [class*="author"], [id*="author"]').length > 0 ||
                    /작성자|author|by\s+\w+/i.test(text);
  const hasEditor = /편집자|editor|edited\s+by/i.test(text);
  const accountabilityScore = (hasAuthor ? 60 : 0) + (hasEditor ? 40 : 0);
  
  // 4. 공정성 (Fairness)
  const hasBiasDisclosure = /편향|bias|limitation|제한사항/i.test(text);
  const fairnessScore = hasBiasDisclosure ? 100 : 50; // 편향 고지가 없어도 부분 점수
  
  // 5. 프라이버시 (Privacy)
  const hasPrivacyNotice = /개인정보|privacy|개인\s*정보/i.test(text) ||
                          $('a[href*="privacy"], a[href*="개인정보"]').length > 0;
  const privacyScore = hasPrivacyNotice ? 100 : 0;
  
  // 종합 점수 (가중 평균)
  const overallScore = Math.round(
    transparencyScore * 0.35 +  // 투명성이 가장 중요
    accuracyScore * 0.25 +
    accountabilityScore * 0.20 +
    fairnessScore * 0.10 +
    privacyScore * 0.10
  );

  return {
    transparency: {
      score: transparencyScore,
      hasDisclosure: hasAIDisclosure,
      issues: hasAIDisclosure ? [] : ['AI 활용에 대한 명시적 고지가 없습니다.'],
    },
    accuracy: {
      score: accuracyScore,
      hasFactChecking: hasFactChecking,
      hasSources: hasSources,
      issues: [
        !hasSources && '출처나 참고 자료가 명시되지 않았습니다.',
        !hasFactChecking && '사실 확인 절차가 명시되지 않았습니다.',
      ].filter(Boolean) as string[],
    },
    accountability: {
      score: accountabilityScore,
      hasAuthor: hasAuthor,
      hasEditor: hasEditor,
      issues: [
        !hasAuthor && '작성자 정보가 명시되지 않았습니다.',
        !hasEditor && '편집자 정보가 명시되지 않았습니다.',
      ].filter(Boolean) as string[],
    },
    fairness: {
      score: fairnessScore,
      hasBiasDisclosure: hasBiasDisclosure,
      issues: !hasBiasDisclosure ? ['AI 모델의 편향성이나 제한사항에 대한 고지가 없습니다.'] : [],
    },
    privacy: {
      score: privacyScore,
      hasPrivacyNotice: hasPrivacyNotice,
      issues: !hasPrivacyNotice ? ['개인정보 처리에 대한 고지가 없습니다.'] : [],
    },
    overallScore,
  };
}
```

### 4.5 종합 점수 계산 모듈 (`disclosure-scorer.ts`)

```typescript
import { AIDisclosureResult } from './ai-disclosure-detector';
import { SynthIDResult } from './synthid-detector';
import { EthicsComplianceResult } from './ai-ethics-analyzer';

export interface AIDisclosureScore {
  disclosureScore: number; // 0-100
  synthidScore: number; // 0-100
  ethicsScore: number; // 0-100
  overallScore: number; // 0-100
  recommendations: string[];
}

/**
 * AI 활용 고지 종합 점수 계산
 */
export function calculateAIDisclosureScore(
  disclosure: AIDisclosureResult,
  synthid: SynthIDResult,
  ethics: EthicsComplianceResult
): AIDisclosureScore {
  // 1. 고지 점수 (40% 가중치)
  const disclosureScore = disclosure.hasExplicitDisclosure 
    ? Math.min(100, 70 + disclosure.confidence * 0.3) // 기본 70점 + 신뢰도 보너스
    : 0;

  // 2. SynthID 탐지 점수 (20% 가중치)
  // 워터마킹이 있으면 투명성 점수에 보너스
  const synthidScore = synthid.hasWatermark 
    ? Math.min(100, 50 + synthid.confidence * 0.5)
    : 50; // 워터마킹이 없어도 부분 점수 (AI 생성이 아닐 수 있음)

  // 3. 윤리 점수 (40% 가중치)
  const ethicsScore = ethics.overallScore;

  // 종합 점수
  const overallScore = Math.round(
    disclosureScore * 0.4 +
    synthidScore * 0.2 +
    ethicsScore * 0.4
  );

  // 권장사항 생성
  const recommendations: string[] = [];
  
  if (!disclosure.hasExplicitDisclosure) {
    recommendations.push('콘텐츠에 AI 활용에 대한 명시적 고지를 추가하세요.');
  }
  
  if (disclosure.disclosureLocation === 'body' && disclosure.hasExplicitDisclosure) {
    recommendations.push('AI 활용 고지를 헤더나 메타 태그에도 추가하면 더 명확합니다.');
  }

  if (ethics.transparency.score < 50) {
    recommendations.push('AI 활용 투명성을 높이기 위해 명시적 고지를 추가하세요.');
  }

  if (ethics.accuracy.score < 70) {
    recommendations.push('출처와 사실 확인 정보를 명시하여 정확성을 높이세요.');
  }

  if (ethics.accountability.score < 70) {
    recommendations.push('작성자 및 편집자 정보를 명시하여 책임성을 높이세요.');
  }

  return {
    disclosureScore,
    synthidScore,
    ethicsScore,
    overallScore,
    recommendations,
  };
}
```

### 4.6 `analyzer.ts` 통합

```typescript
// analyzer.ts에 추가
import { detectAIDisclosure } from './ai-disclosure-detector';
import { detectSynthIDWatermark } from './synthid-detector';
import { evaluateAIEthics } from './ai-ethics-analyzer';
import { calculateAIDisclosureScore } from './disclosure-scorer';

export interface AnalysisResult {
  // ... 기존 필드
  aiDisclosureAnalysis?: {
    disclosureScore: number;
    synthidScore: number;
    ethicsScore: number;
    overallScore: number;
    recommendations: string[];
    details: {
      explicitDisclosure: AIDisclosureResult;
      synthidDetection: SynthIDResult;
      ethicsCompliance: EthicsComplianceResult;
    };
  };
}

// analyzeContent 함수 내부에 추가
export async function analyzeContent(url: string): Promise<AnalysisResult> {
  // ... 기존 분석 로직

  // AI 활용 고지 탐지
  const explicitDisclosure = detectAIDisclosure($, html);
  const synthidDetection = detectSynthIDWatermark($, html);
  const ethicsCompliance = evaluateAIEthics($, html);
  const aiDisclosureScore = calculateAIDisclosureScore(
    explicitDisclosure,
    synthidDetection,
    ethicsCompliance
  );

  return {
    // ... 기존 결과
    aiDisclosureAnalysis: {
      disclosureScore: aiDisclosureScore.disclosureScore,
      synthidScore: aiDisclosureScore.synthidScore,
      ethicsScore: aiDisclosureScore.ethicsScore,
      overallScore: aiDisclosureScore.overallScore,
      recommendations: aiDisclosureScore.recommendations,
      details: {
        explicitDisclosure,
        synthidDetection,
        ethicsCompliance,
      },
    },
  };
}
```

---

## 5. 데이터베이스 스키마 변경

### 5.1 `analyses` 테이블 확장

```sql
-- 기존 테이블에 컬럼 추가
ALTER TABLE analyses ADD COLUMN ai_disclosure_score INTEGER;
ALTER TABLE analyses ADD COLUMN ai_synthid_score INTEGER;
ALTER TABLE analyses ADD COLUMN ai_ethics_score INTEGER;
ALTER TABLE analyses ADD COLUMN ai_disclosure_overall_score INTEGER;

-- JSON 필드로 상세 정보 저장 (선택사항)
ALTER TABLE analyses ADD COLUMN ai_disclosure_details TEXT; -- JSON
```

### 5.2 마이그레이션 스크립트

```typescript
// lib/migrations/004_add_ai_disclosure_scores.ts
export async function migrate004AddAIDisclosureScores() {
  const db = await import('../db').then(m => m.default);
  
  try {
    // SQLite
    if (process.env.DATABASE_URL?.startsWith('sqlite')) {
      db.exec(`
        ALTER TABLE analyses ADD COLUMN ai_disclosure_score INTEGER;
        ALTER TABLE analyses ADD COLUMN ai_synthid_score INTEGER;
        ALTER TABLE analyses ADD COLUMN ai_ethics_score INTEGER;
        ALTER TABLE analyses ADD COLUMN ai_disclosure_overall_score INTEGER;
        ALTER TABLE analyses ADD COLUMN ai_disclosure_details TEXT;
      `);
    } else {
      // PostgreSQL
      await db.query(`
        ALTER TABLE analyses 
        ADD COLUMN IF NOT EXISTS ai_disclosure_score INTEGER,
        ADD COLUMN IF NOT EXISTS ai_synthid_score INTEGER,
        ADD COLUMN IF NOT EXISTS ai_ethics_score INTEGER,
        ADD COLUMN IF NOT EXISTS ai_disclosure_overall_score INTEGER,
        ADD COLUMN IF NOT EXISTS ai_disclosure_details TEXT;
      `);
    }
    
    console.log('✅ Migration 004: AI disclosure scores columns added');
  } catch (error) {
    console.error('❌ Migration 004 failed:', error);
    throw error;
  }
}
```

---

## 6. UI/UX 변경사항

### 6.1 `ScoreChart.tsx` 확장

```typescript
interface ScoreChartProps {
  // ... 기존 props
  aiDisclosureAnalysis?: {
    disclosureScore: number;
    synthidScore: number;
    ethicsScore: number;
    overallScore: number;
  };
}

// 차트에 AI 활용 고지 점수 추가
const allScores = {
  labels: [
    'AEO', 'GEO', 'SEO', '종합',
    'ChatGPT', 'Perplexity', 'Gemini', 'Claude',
    'AI 고지', 'SynthID', 'AI 윤리', 'AI 투명성 종합'
  ],
  data: [
    aeoScore, geoScore, seoScore, overallScore,
    aioAnalysis?.scores.chatgpt || 0,
    aioAnalysis?.scores.perplexity || 0,
    aioAnalysis?.scores.gemini || 0,
    aioAnalysis?.scores.claude || 0,
    aiDisclosureAnalysis?.disclosureScore || 0,
    aiDisclosureAnalysis?.synthidScore || 0,
    aiDisclosureAnalysis?.ethicsScore || 0,
    aiDisclosureAnalysis?.overallScore || 0,
  ],
};
```

### 6.2 새로운 컴포넌트: `AIDisclosureCard.tsx`

```typescript
'use client';

interface AIDisclosureCardProps {
  analysis: {
    disclosureScore: number;
    synthidScore: number;
    ethicsScore: number;
    overallScore: number;
    recommendations: string[];
    details: {
      explicitDisclosure: AIDisclosureResult;
      synthidDetection: SynthIDResult;
      ethicsCompliance: EthicsComplianceResult;
    };
  };
}

export default function AIDisclosureCard({ analysis }: AIDisclosureCardProps) {
  return (
    <div className="rounded-lg border border-gray-200 dark:border-gray-800 bg-white dark:bg-gray-800 p-6 shadow-sm">
      <h3 className="text-lg font-semibold mb-4">AI 활용 고지 분석</h3>
      
      {/* 점수 표시 */}
      <div className="grid grid-cols-2 md:grid-cols-4 gap-4 mb-6">
        <div>
          <div className="text-sm text-gray-600 dark:text-gray-400">고지 점수</div>
          <div className="text-2xl font-bold">{analysis.disclosureScore}</div>
        </div>
        <div>
          <div className="text-sm text-gray-600 dark:text-gray-400">SynthID 탐지</div>
          <div className="text-2xl font-bold">{analysis.synthidScore}</div>
        </div>
        <div>
          <div className="text-sm text-gray-600 dark:text-gray-400">윤리 점수</div>
          <div className="text-2xl font-bold">{analysis.ethicsScore}</div>
        </div>
        <div>
          <div className="text-sm text-gray-600 dark:text-gray-400">종합 점수</div>
          <div className="text-2xl font-bold text-blue-600">{analysis.overallScore}</div>
        </div>
      </div>

      {/* 상세 정보 */}
      <div className="space-y-4">
        <div>
          <h4 className="font-medium mb-2">명시적 고지</h4>
          <div className="text-sm text-gray-600 dark:text-gray-400">
            {analysis.details.explicitDisclosure.hasExplicitDisclosure ? (
              <span className="text-green-600">✓ 탐지됨 ({analysis.details.explicitDisclosure.disclosureType})</span>
            ) : (
              <span className="text-red-600">✗ 탐지되지 않음</span>
            )}
          </div>
        </div>

        <div>
          <h4 className="font-medium mb-2">윤리 준수</h4>
          <div className="space-y-2">
            <div className="flex justify-between text-sm">
              <span>투명성</span>
              <span>{analysis.details.ethicsCompliance.transparency.score}점</span>
            </div>
            <div className="flex justify-between text-sm">
              <span>정확성</span>
              <span>{analysis.details.ethicsCompliance.accuracy.score}점</span>
            </div>
            <div className="flex justify-between text-sm">
              <span>책임성</span>
              <span>{analysis.details.ethicsCompliance.accountability.score}점</span>
            </div>
          </div>
        </div>

        {/* 권장사항 */}
        {analysis.recommendations.length > 0 && (
          <div>
            <h4 className="font-medium mb-2">개선 권장사항</h4>
            <ul className="list-disc list-inside space-y-1 text-sm text-gray-600 dark:text-gray-400">
              {analysis.recommendations.map((rec, i) => (
                <li key={i}>{rec}</li>
              ))}
            </ul>
          </div>
        )}
      </div>
    </div>
  );
}
```

---

## 7. API 변경사항

### 7.1 `/api/analyze` 응답 확장

```typescript
// app/api/analyze/route.ts
const result = await analyzeContent(sanitizedUrl);

// 저장 시 AI 활용 고지 점수도 저장
await saveAnalysis({
  // ... 기존 필드
  aiDisclosureScore: result.aiDisclosureAnalysis?.disclosureScore,
  aiSynthidScore: result.aiDisclosureAnalysis?.synthidScore,
  aiEthicsScore: result.aiDisclosureAnalysis?.ethicsScore,
  aiDisclosureOverallScore: result.aiDisclosureAnalysis?.overallScore,
});
```

---

## 8. 기술적 고려사항 및 제약사항

### 8.1 Google SynthID 탐지의 한계

**현재 제약사항:**
- Google SynthID Detector API가 공개적으로 제공되지 않음
- 워터마킹은 통계적 패턴 기반이므로 완벽한 탐지 어려움
- 텍스트 편집/파라프레이징으로 워터마킹 제거 가능

**대응 방안:**
- 통계적 패턴 분석으로 간접 탐지
- 향후 API 공개 시 통합 준비
- 명시적 고지 탐지에 더 집중

### 8.2 성능 고려사항

- **분석 시간 증가**: 추가 분석으로 인한 처리 시간 증가 예상 (약 200-500ms)
- **캐싱 활용**: 동일 URL 재분석 시 캐시 활용
- **비동기 처리**: 필요 시 AI 윤리 분석을 비동기로 처리

### 8.3 정확도 제한

- **패턴 매칭 기반**: 정규식 기반 탐지는 오탐/미탐 가능
- **언어 지원**: 현재 한국어/영어 중심, 다른 언어 지원 필요 시 확장
- **컨텍스트 이해**: 자연어 처리 없이는 문맥적 이해 제한적

### 8.4 법적/윤리적 고려사항

- **규정 변화**: AI 윤리 규정이 빠르게 변화하므로 정기적 업데이트 필요
- **지역별 차이**: EU, 미국, 한국 등 지역별 규정 차이 고려
- **과도한 판단 지양**: 점수는 참고용이며 법적 판단 대체 불가

---

## 9. 구현 단계

### Phase 1: 기본 탐지 기능 (2주)
1. `ai-disclosure-detector.ts` 구현
2. 명시적 고지 탐지 기능
3. 기본 점수 계산

### Phase 2: SynthID 및 윤리 분석 (2주)
1. `synthid-detector.ts` 구현
2. `ai-ethics-analyzer.ts` 구현
3. 종합 점수 계산

### Phase 3: 통합 및 UI (1주)
1. `analyzer.ts` 통합
2. 데이터베이스 마이그레이션
3. UI 컴포넌트 개발

### Phase 4: 테스트 및 최적화 (1주)
1. 다양한 콘텐츠 테스트
2. 성능 최적화
3. 문서화

---

## 10. 향후 개선 방향

### 10.1 고도화
- **머신러닝 기반 탐지**: AI 생성 텍스트 분류 모델 통합
- **이미지 분석**: SynthID 이미지 워터마킹 탐지 (이미지 다운로드 및 분석)
- **다국어 지원**: 더 많은 언어 패턴 지원

### 10.2 API 통합
- **Google SynthID Detector API**: 공개 시 즉시 통합
- **OpenAI Content Classifier**: OpenAI의 AI 탐지 도구 통합
- **기타 탐지 서비스**: Hugging Face, OpenAI 등 다양한 서비스 통합

### 10.3 규정 추적
- **자동 업데이트**: 최신 AI 윤리 규정 자동 반영
- **지역별 맞춤**: 사용자 지역에 따른 규정 적용
- **규정 변경 알림**: 중요한 규정 변경 시 사용자 알림

---

## 11. 결론

AI 활용 고지 탐지 기능은 다음과 같은 가치를 제공합니다:

1. **투명성 향상**: 콘텐츠의 AI 활용 여부 명확화
2. **법적 준수**: AI 윤리 규정 준수 지원
3. **신뢰성 강화**: 사용자 신뢰도 향상
4. **경쟁력**: AI 투명성 측면에서 차별화

**기술적 실현 가능성**: 높음
- 명시적 고지 탐지: 구현 용이
- SynthID 탐지: 제한적이지만 기본 탐지 가능
- AI 윤리 평가: 규칙 기반 평가로 구현 가능

**권장사항**: 
- Phase 1부터 단계적 구현
- 사용자 피드백 수집 및 개선
- 최신 규정 및 기술 동향 모니터링
